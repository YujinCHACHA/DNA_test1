{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YujinCHACHA/DNA_test1/blob/main/Testing_TFLite_model_v2_sound_tf_fin_del_lite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKFUvuEho9Th"
      },
      "source": [
        "# Testing TensorFlow Lite models\n",
        "\n",
        "This notebooks shows some ways for debugging TensorFlow Lite models and comparing them with the original implementations in TensorFlow.\n",
        "\n",
        "For more details, take a look at blog posts:\n",
        "\n",
        "- [Testing TensorFlow Lite image classification model](https://thinkmobile.dev/testing-tensorflow-lite-image-classification-model/) - converting TensorFlow to TensorFlow Lite and comparing models side by side.\n",
        "- [Automate testing of TensorFlow Lite model implementation](https://thinkmobile.dev/automate-testing-of-tensorflow-lite-model-implementation/) - Testing TensorFlow Lite model on Android app with Espresso and instrumented tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bppPn2X_N2hN"
      },
      "source": [
        "<TensorFlow Lite 모델 테스트>\n",
        "\n",
        "이 노트북은 TensorFlow Lite 모델을 디버깅하고 이를 TensorFlow의 원래 구현과 비교하는 몇 가지 방법을 보여줍니다.\n",
        "\n",
        "자세한 내용은 블로그 게시물을 참조하세요.\n",
        "\n",
        "- [TensorFlow Lite 이미지 분류 모델 테스트](https://thinkmobile.dev/testing-tensorflow-lite-image-classification-model/) - TensorFlow를 TensorFlow Lite로 변환하고 모델을 나란히 비교합니다.\n",
        "- [TensorFlow Lite 모델 구현 테스트 자동화](https://thinkmobile.dev/automate-testing-of-tensorflow-lite-model-implementation/) - Espresso 및 계측 테스트를 사용하여 Android 앱에서 TensorFlow Lite 모델 테스트."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtarLRYLEgUE"
      },
      "source": [
        "### How accurate is this notebook?\n",
        "\n",
        "It's worth to mention, that this notebook shows just some basic ideas for eye-comparison between TensorFlow and TensorFlow Lite models. It doesn't check them for speed and any other factor of performance and doesn't do any accurate side-by-side comparison. But still can be helpful with answering the question \"why a model implemented on the app doesn't work the same like on notebook?\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJt1SRakN2hS"
      },
      "source": [
        "--이 노트는 얼마나 정확합니까?\n",
        "\n",
        "이 노트북은 TensorFlow와 TensorFlow Lite 모델 간의 눈 비교를 위한 몇 가지 기본 아이디어만 보여줍니다. 속도 및 기타 성능 요인을 확인하지 않으며 정확한 나란히 비교도 수행하지 않습니다. 그러나 \"앱에 구현된 모델이 노트북에서와 같이 작동하지 않는 이유는 무엇입니까?\"라는 질문에 답하는 데 여전히 도움이 될 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1bgQLCCEcP5"
      },
      "source": [
        "## TensorFlow 2.0 and Colaboratory\n",
        "\n",
        "This notebook can be executed in Colaboratory. It requires some changes to make it working on Docker environment described in linked blog post.\n",
        "\n",
        "Examples presented in this notebook are built on top of TensorFlow 2.0 stable version.\n",
        "\n",
        "### GPU support\n",
        "The good thing about Colab is that it supports GPU envinronment without additional work. Just open **Runtime -> Change runtime type** and make sure that GPU is selected. The training process of this notebook should be about 3 times faster than on CPU env."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZtr_Lo_N2hW"
      },
      "source": [
        "-TensorFlow 2.0 및 Colaboratory\n",
        "\n",
        "이 노트북은 Colaboratory에서 실행할 수 있습니다. 링크된 블로그 게시물에 설명된 Docker 환경에서 작동하려면 약간의 변경이 필요합니다.\n",
        "\n",
        "이 노트북에 제시된 예제는 TensorFlow 2.0 안정 버전을 기반으로 구축되었습니다.\n",
        "\n",
        "--GPU 지원\n",
        "Colab의 좋은 점은 추가 작업 없이 GPU 환경을 지원한다는 것입니다. **런타임 -> 런타임 유형 변경**을 열고 GPU가 선택되어 있는지 확인하십시오. 이 노트북의 훈련 과정은 CPU 환경보다 약 3배 빨라야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAfFB-e2N2hZ"
      },
      "outputs": [],
      "source": [
        "'''import os, re, glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "groups_folder_path = './cnn_sample/'\n",
        "categories = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",\n",
        "              \"A\", \"C\", \"D\", \"E\", \"F\", \"H\", \"J\",\"K\", \"L\", \"M\",\n",
        "              \"N\", \"R\", \"S\", \"T\", \"X\", \"Y\", \"Z\"]\n",
        "\n",
        "num_classes = len(categories)\n",
        " \n",
        "image_w = 28\n",
        "image_h = 28\n",
        " \n",
        "X = []\n",
        "Y = []\n",
        " \n",
        "for idex, categorie in enumerate(categories):\n",
        "    label = [0 for i in range(num_classes)]\n",
        "    label[idex] = 1\n",
        "    image_dir = groups_folder_path + categorie + '/'\n",
        " \n",
        "    for top, dir, f in os.walk(image_dir):\n",
        "        for filename in f:\n",
        "            print(image_dir+filename)\n",
        "            img = cv2.imread(image_dir+filename)\n",
        "            img = cv2.resize(img, None, fx=image_w/img.shape[1], fy=image_h/img.shape[0])\n",
        "            X.append(img/256)\n",
        "            Y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
        "xy = (X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "np.save(\"./img_data.npy\", xy)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x6yYGmQ_mnu"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow-gpu==2.0.0\n",
        "#!pip install tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGNpmn43C0O6"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dnte2wCK-cw"
      },
      "source": [
        "For better data visualization we'll use [Pandas library](https://pandas.pydata.org/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Z9vFE1IQ2Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Increase precision of presented data for better side-by-side comparison\n",
        "pd.set_option(\"display.precision\", 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "H0j5p4zf0S2i",
        "outputId": "aa50bf72-7606-4781-b499-4d478e78e2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Version:  2.6.2\n",
            "Hub version:  0.12.0\n",
            "Eager mode:  True\n",
            "GPU is NOT AVAILABLE\n"
          ]
        }
      ],
      "source": [
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amfzqn1Oo7Om"
      },
      "source": [
        "## Simple transfer learning(단순 전이 학습)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-nIpVJ94xrw"
      },
      "source": [
        "For the sake of the notebook completness, we will do simple transfer learning, to create our own machine learning model. \n",
        "\n",
        "If you want to know more about it, I highly recommend to check Udacity [\"Tensorflow free course\"](https://classroom.udacity.com/courses/ud187), where the inspiration for transfer learning code came from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33fJpTaDN2hs"
      },
      "source": [
        "노트북의 완성도를 위해 간단한 전이 학습을 수행하여 자체 기계 학습 모델을 만듭니다.\n",
        "\n",
        "이에 대해 더 알고 싶다면 전이 학습 코드의 영감을 얻은 Udacity [\"Tensorflow 무료 과정\"](https://classroom.udacity.com/courses/ud187)를 확인하는 것이 좋습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z93vvAdGxDMD"
      },
      "source": [
        "### Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4lDPkn2cpWZ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Learn more about data batches\n",
        "#Image batch shape:  (32, 224, 224, 3)\n",
        "#Label batch shape:  (32, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlmFuhf5N2hu",
        "outputId": "57087523-6dec-46af-a55f-975a85f87582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "folder_list ['babbling', 'car_noise', 'voice', 'white_noise']\n"
          ]
        }
      ],
      "source": [
        "path_root = './dataset_img_128'\n",
        "folder_list = os.listdir(path_root)\n",
        "print('folder_list',folder_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQr3KatbN2hw",
        "outputId": "2987ae8f-e251-4cde-c28e-b23bcdcf0a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\envs\\s6\\lib\\site-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.13.3; python_version < \"3.7\" in c:\\programdata\\anaconda3\\envs\\s6\\lib\\site-packages (from opencv-python) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmEaCigrN2hx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLQYheibN2hy"
      },
      "outputs": [],
      "source": [
        "image_w = 224\n",
        "image_h = 224\n",
        "data_feature = []\n",
        "data_label = []\n",
        "idx_plot = 0\n",
        "for index in range(len(folder_list)):\n",
        "    path_file = os.path.join(path_root, folder_list[index])\n",
        "    \n",
        "    img_list = os.listdir(path_file)\n",
        "    for img in img_list:\n",
        "        \n",
        "        img_path = os.path.join(path_file, img)\n",
        "        '''img = cv2.cv2.imread(img_path, cv2.IMREAD_COLOR)'''\n",
        "        img = cv2.imread(img_path) #, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, None, fx=image_w/img.shape[1], fy=image_h/img.shape[0])\n",
        "        data_feature.append(img/255)\n",
        "        data_label.append(index)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEz3lmleN2hz",
        "outputId": "ea0bab33-a030-481f-d64c-188a762ef26e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "np.shape(data_feature) (412, 224, 224, 3)\n",
            "np.shape(data_label) (412,)\n",
            "data_label[:4] [0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print('np.shape(data_feature)', np.shape(data_feature))\n",
        "print('np.shape(data_label)', np.shape(data_label))\n",
        "print('data_label[:4]', data_label[:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcXAKKFVN2h0"
      },
      "source": [
        "num_color = 3\n",
        "data_feature = tf.reshape(data_feature, [-1, image_w, image_h, num_color]) \n",
        "print('np.shape(data_feature)', np.shape(data_feature))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "hrJhAFZNN2h1"
      },
      "outputs": [],
      "source": [
        "data_label = to_categorical(data_label, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXdHXC2iN2h2"
      },
      "outputs": [],
      "source": [
        "data_feature = np.array(data_feature)\n",
        "data_label = np.array(data_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qysW6uclN2h3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0aVhDICN2h3",
        "outputId": "fd7cd6a7-1865-4e63-a205-fcd316dc0ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label_train [[0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "feature_train, feature_test, label_train, label_test = train_test_split(data_feature,data_label)\n",
        "print('label_train',label_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPVeouTksO9q"
      },
      "source": [
        "### Model architecture, training\n",
        "\n",
        "As a base model for transfer learning, we'll use MobileNet v2 model stored on TensorFlow Hub. Presented model can be used only in TensorFlow 2.0 implementation (TF Hub contains also models for TensorFlow 1.x).\n",
        "\n",
        "Basic information about feature vector:\n",
        "- Input shape: 224x224x3 (224x224 pixels, 3 chanels each, RGB format),\n",
        "- Each channel has value in range [0, 1],\n",
        "- Feature vector output shape: 1280 (number of labels classified by MobileNet is 1001 - this info isn't important here)\n",
        "\n",
        "For more details check feature vector page:\n",
        "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxJY0DJIN2h5"
      },
      "source": [
        "--모델 아키텍처, 교육\n",
        "\n",
        "전이 학습의 기본 모델로 TensorFlow Hub에 저장된 MobileNet v2 모델을 사용합니다. 제시된 모델은 TensorFlow 2.0 구현에서만 사용할 수 있습니다(TF Hub에는 TensorFlow 1.x용 모델도 포함되어 있음).\n",
        "\n",
        "특징 벡터에 대한 기본 정보:\n",
        "- 입력 형태: 224x224x3 (224x224 픽셀, 각 3채널, RGB 형식),\n",
        "- 각 채널은 [0, 1] 범위의 값을 가지며,\n",
        "- Feature vector output shape: 1280 (MobileNet에 의해 분류된 레이블의 수는 1001 - 이 정보는 중요하지 않음)\n",
        "\n",
        "자세한 내용은 기능 벡터 페이지를 확인하십시오.\n",
        "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "mGcY27fY1q3Q",
        "outputId": "2792713a-6069-4f95-f556-ddd3f52d3f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_6 (KerasLayer)   (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4)                 5124      \n",
            "=================================================================\n",
            "Total params: 2,263,108\n",
            "Trainable params: 5,124\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(folder_list)\n",
        "model = tf.keras.Sequential([\n",
        "  hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\", \n",
        "                 output_shape=[1280],\n",
        "                 trainable=False),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.build([None, image_w, image_h, num_color])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n0Wb9ylKd8R"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "EyMDJxt2HdHr",
        "outputId": "4089410f-a9a4-46e7-d2dd-f2925f91c2f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "8/8 [==============================] - 8s 689ms/step - loss: 1.5075 - acc: 0.3117 - val_loss: 1.1244 - val_acc: 0.5323\n",
            "Epoch 2/6\n",
            "8/8 [==============================] - 5s 585ms/step - loss: 1.1577 - acc: 0.4939 - val_loss: 0.8543 - val_acc: 0.8548\n",
            "Epoch 3/6\n",
            "8/8 [==============================] - 5s 601ms/step - loss: 0.8486 - acc: 0.6518 - val_loss: 0.7154 - val_acc: 0.7419\n",
            "Epoch 4/6\n",
            "8/8 [==============================] - 5s 602ms/step - loss: 0.7208 - acc: 0.7490 - val_loss: 0.6495 - val_acc: 0.8548\n",
            "Epoch 5/6\n",
            "8/8 [==============================] - 4s 571ms/step - loss: 0.6207 - acc: 0.7976 - val_loss: 0.5802 - val_acc: 0.8710\n",
            "Epoch 6/6\n",
            "8/8 [==============================] - 5s 583ms/step - loss: 0.5274 - acc: 0.8259 - val_loss: 0.4878 - val_acc: 0.8548\n"
          ]
        }
      ],
      "source": [
        "# Run model training\n",
        "\n",
        "hist = model.fit(feature_train, label_train, validation_split = 0.2, epochs=6, verbose=1).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "j93MXHpYFrT_",
        "outputId": "a0e2274c-e586-42db-a52e-50764f80d0ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x22df2ab1e48>]"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize training process\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"acc\"])\n",
        "plt.plot(hist[\"val_acc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "GlfrTTAUEIZ1",
        "outputId": "a7c0198f-af4f-4cdf-ad4b-2883106f7ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 2s 362ms/step - loss: 0.4440 - acc: 0.8350\n"
          ]
        }
      ],
      "source": [
        "# Measure accuracy and loss after training\n",
        "\n",
        "final_loss, final_accuracy = model.evaluate(feature_test, label_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "Ho43qcQGEQFb",
        "outputId": "fe30b23b-8e53-4815-f684-021bac50be77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final loss: 0.44\n",
            "Final accuracy: 83.50%\n"
          ]
        }
      ],
      "source": [
        "print(\"Final loss: {:.2f}\".format(final_loss))\n",
        "print(\"Final accuracy: {:.2f}%\".format(final_accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRcJnAABr22x"
      },
      "source": [
        "### Export your model\n",
        "\n",
        "We'll save our model as TensorFlow SavedModel format. After that we'll do inference on reloaded model, so if you come with a model already trained, it'll be easier to inspect it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoYSfwSN2iA"
      },
      "source": [
        "-- 모델 내보내기\n",
        "\n",
        "모델을 TensorFlow SavedModel 형식으로 저장합니다. 그 후에 우리는 다시 로드된 모델에 대한 추론을 수행할 것이므로 이미 훈련된 모델과 함께 오는 경우 모델을 검사하기가 더 쉬울 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLcqg-RmsLno"
      },
      "outputs": [],
      "source": [
        "'''FLOWERS_SAVED_MODEL = \"./saved_models/\"\n",
        "tf.saved_model.save(model, FLOWERS_SAVED_MODEL)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG6ndR1RItts"
      },
      "source": [
        "## Load TensorFlow SavedModel\n",
        "\n",
        "Let's load TensorFlow model from SavedModel format. Because we used custom layer from TensorFlow Hub, we need to explicitly point out the implementation with `custom_obiects` param."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpkHSuiAN2iC"
      },
      "source": [
        "-TensorFlow 저장된 모델 로드\n",
        "\n",
        "SavedModel 형식에서 TensorFlow 모델을 로드해 보겠습니다. TensorFlow Hub의 커스텀 레이어를 사용했기 때문에 `custom_obiects` 매개변수로 구현을 명시적으로 지적해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nI5fvkAQvbS",
        "outputId": "b367d251-60b4-4169-ad3d-67d046cfcce6"
      },
      "source": [
        "# Load SavedModel(저장된 모델 불러오기)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXJxIDBJN2iD"
      },
      "outputs": [],
      "source": [
        "'''flowers_model = hub.load(FLOWERS_SAVED_MODEL)\n",
        "print(flowers_model)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yM9UeUnF8t7"
      },
      "source": [
        "## Convert model to TFLite\n",
        "\n",
        "Convert recently loaded model to TensorFlow Lite models (standard and quantized with a [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization)).\n",
        "\n",
        "Because of TensorFlow 2.0 nature, we'll need to convert TensorFlow model into concrete function and then do conversion to TFLite. More about it [here](https://www.tensorflow.org/lite/r2/convert/concrete_function)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iSDKvd9N2iE"
      },
      "source": [
        "-모델을 TFLite로 변환\n",
        "\n",
        "최근에 로드된 모델을 TensorFlow Lite 모델로 변환합니다(표준 및 [훈련 후 양자화](https://www.tensorflow.org/lite/performance/post_training_quantization)로 양자화됨).\n",
        "\n",
        "TensorFlow 2.0 특성상 TensorFlow 모델을 구체적인 함수로 변환한 다음 TFLite로 변환해야 합니다. [여기](https://www.tensorflow.org/lite/r2/convert/concrete_function)에 대해 자세히 알아보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXjmRTncPr3c"
      },
      "outputs": [],
      "source": [
        "'''!mkdir \"tflite_models\"'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00O-I9wKPwMn"
      },
      "outputs": [],
      "source": [
        "'''TFLITE_MODEL = \"tflite_models/flowers.tflite\"\n",
        "TFLITE_QUANT_MODEL = \"tflite_models/flowers_quant.tflite\"'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOJZlacLG5e7",
        "outputId": "254eab8e-8101-41e2-e7f9-7232f1c45893"
      },
      "source": [
        "# Get the concrete function from the Keras model.(케라스모델로부터 구체적인 함수를 가져와라)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "q_TfRDGxN2iH",
        "outputId": "40963b00-acbf-4cc4-e99a-3cd48be0c39d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'run_model = tf.function(lambda x : flowers_model(x))'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''run_model = tf.function(lambda x : flowers_model(x))'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhZEwloIN2iI"
      },
      "source": [
        "# Save the concrete function. (구체적인 함수를 저장하라.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_bLChF9N2iI",
        "outputId": "cc2e96ca-aa45-4d36-e5d1-213f71597e48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'concrete_func = run_model.get_concrete_function(\\n    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\\n)'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
        ")'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-tWfTn4N2iJ"
      },
      "source": [
        "# Convert the model(모델을 바꿔라.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SoFlx4hN2iK",
        "outputId": "3b580d33-0542-466f-8af8-002a7ca37bb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\\nconverted_tflite_model = converter.convert()\\nopen(TFLITE_MODEL, \"wb\").write(converted_tflite_model)'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converted_tflite_model = converter.convert()\n",
        "open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih4N4p7nN2iK"
      },
      "source": [
        "# Convert the model to quantized version with post-training quantization\n",
        "#훈련 후 양자화를 통해 모델을 양자화 버전으로 변환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp9ALcmxN2iL"
      },
      "outputs": [],
      "source": [
        "'''converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_quant_model = converter.convert()\n",
        "open(TFLITE_QUANT_MODEL, \"wb\").write(tflite_quant_model)\n",
        "\n",
        "print(\"TFLite models and their sizes:\")\n",
        "!ls \"tflite_models\" -lh'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX3Nv5LMGAja"
      },
      "source": [
        "### Load TFLite model (TFLite 모델 로드하기)\n",
        "\n",
        "Load TensorFlow lite model with interpreter interface.(인터프리터 인터페이스로 TensorFlow 라이트 모델을 로드합니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoBmFmXlHVhj",
        "outputId": "8c5ced6a-6544-4f2a-cb2f-a36fade07278"
      },
      "source": [
        "# Load TFLite model and see some details about input/output\n",
        "#TFLite 모델을 로드하고 입력값/출력값의 세부사항을 살펴라."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In_s5ydtN2iN"
      },
      "outputs": [],
      "source": [
        "'''tflite_interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"name:\", input_details[0]['name'])\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"name:\", output_details[0]['name'])\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKd2v0ldRess"
      },
      "source": [
        "#### Resize input and output tensors shapes (입력값과 출력값의 텐서 모양을 바꿔라.)\n",
        "\n",
        "Input shape of loaded TFLite model is 1x224x224x3, what means that we can make predictions for single image.\n",
        "Let's resize input and output tensors, so we can make predictions for batch of 32 images.\n",
        " (로드된 TFLite 모델의 입력 형태는 1x224x224x3이며, 이는 단일 이미지에 대한 예측을 할 수 있음을 의미합니다.\n",
        "입력 및 출력 텐서의 크기를 조정하여 32개의 이미지 배치를 예측할 수 있도록 합시다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "VXX8lJkPRYFq",
        "outputId": "ae5744fe-22af-4501-e60a-3f0eab5bbe12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tflite_interpreter.resize_tensor_input(input_details[0][\\'index\\'], (1, 224, 224, num_color)) # 32\\ntflite_interpreter.resize_tensor_input(output_details[0][\\'index\\'], (1, num_classes)) # 32\\ntflite_interpreter.allocate_tensors()\\n\\ninput_details = tflite_interpreter.get_input_details()\\noutput_details = tflite_interpreter.get_output_details()\\n\\nprint(\"== Input details ==\")\\nprint(\"name:\", input_details[0][\\'name\\'])\\nprint(\"shape:\", input_details[0][\\'shape\\'])\\nprint(\"type:\", input_details[0][\\'dtype\\'])\\n\\nprint(\"\\n== Output details ==\")\\nprint(\"name:\", output_details[0][\\'name\\'])\\nprint(\"shape:\", output_details[0][\\'shape\\'])\\nprint(\"type:\", output_details[0][\\'dtype\\'])'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''tflite_interpreter.resize_tensor_input(input_details[0]['index'], (1, 224, 224, num_color)) # 32\n",
        "tflite_interpreter.resize_tensor_input(output_details[0]['index'], (1, num_classes)) # 32\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"name:\", input_details[0]['name'])\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"name:\", output_details[0]['name'])\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WEyRJNsR5uL"
      },
      "outputs": [],
      "source": [
        "'''tflite_interpreter.set_tensor(input_details[0]['index'], val_image_batch)\n",
        "\n",
        "tflite_interpreter.invoke()\n",
        "\n",
        "tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwfWiDLgTEIc",
        "outputId": "f8738d93-c8a0-415c-f8b5-11748b232c37"
      },
      "source": [
        "# Convert prediction results to Pandas dataframe, for better visualization\n",
        "(더 나은 시각화를 위해 예측 결과를 Pandas 데이터 프레임으로 변환)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOx8ejrvN2iQ",
        "outputId": "b5b63c40-3bdb-4dde-c6bf-d59615c51dac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tflite_pred_dataframe = pd.DataFrame(tflite_model_predictions)\\ntflite_pred_dataframe.columns = dataset_labels\\n\\nprint(\"TFLite prediction results for the first elements\")\\ntflite_pred_dataframe.head()'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''tflite_pred_dataframe = pd.DataFrame(tflite_model_predictions)\n",
        "tflite_pred_dataframe.columns = dataset_labels\n",
        "\n",
        "print(\"TFLite prediction results for the first elements\")\n",
        "tflite_pred_dataframe.head()'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmJONiLSSe3V"
      },
      "source": [
        "Now let's do the same for TFLite quantized model:\n",
        "- Load model,\n",
        "- Reshape input to handle batch of images,\n",
        "- Run prediction\n",
        "\n",
        "이제 TFLite 양자화 모델에 대해서도 동일한 작업을 수행해 보겠습니다.\n",
        "- 로드 모델,\n",
        "- 이미지 배치를 처리하기 위해 입력 모양 변경,\n",
        "- 예측 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhhw70iYdPIv",
        "outputId": "55ce08da-6eb4-40d9-bb8f-7625b418d359"
      },
      "source": [
        "# Load quantized TFLite model(양자화된 TFLite 모델을 로드하라.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "090_U9_oN2iS",
        "outputId": "62a19b02-d648-4161-c1b6-5b248d10b8ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tflite_interpreter_quant = tf.lite.Interpreter(model_path=TFLITE_QUANT_MODEL)'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''tflite_interpreter_quant = tf.lite.Interpreter(model_path=TFLITE_QUANT_MODEL)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRdo9__EN2iS"
      },
      "source": [
        "# Learn about its input and output details(입력값과 출력값의 세부사항을 배워라.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z26JmfPPN2iT",
        "outputId": "f15c731b-f648-4f01-c063-7f5c4210e709"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'input_details = tflite_interpreter_quant.get_input_details()\\noutput_details = tflite_interpreter_quant.get_output_details()'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''input_details = tflite_interpreter_quant.get_input_details()\n",
        "output_details = tflite_interpreter_quant.get_output_details()'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzScrVAxN2iT"
      },
      "source": [
        "# Resize input and output tensors to handle batch of 32 images(입력값과 출력값의 텐서 모양을 바꿔라. 32장의 이미지 묶음을 처리하기 위해서.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_khI-tUN2iU",
        "outputId": "5d27ef75-7616-4c60-d152-36fe8960f80e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tflite_interpreter_quant.resize_tensor_input(input_details[0][\\'index\\'], (32, 224, 224, 3))\\ntflite_interpreter_quant.resize_tensor_input(output_details[0][\\'index\\'], (32, 5))\\ntflite_interpreter_quant.allocate_tensors()\\n\\ninput_details = tflite_interpreter_quant.get_input_details()\\noutput_details = tflite_interpreter_quant.get_output_details()\\n\\nprint(\"== Input details ==\")\\nprint(\"name:\", input_details[0][\\'name\\'])\\nprint(\"shape:\", input_details[0][\\'shape\\'])\\nprint(\"type:\", input_details[0][\\'dtype\\'])\\n\\nprint(\"\\n== Output details ==\")\\nprint(\"name:\", output_details[0][\\'name\\'])\\nprint(\"shape:\", output_details[0][\\'shape\\'])\\nprint(\"type:\", output_details[0][\\'dtype\\'])'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''tflite_interpreter_quant.resize_tensor_input(input_details[0]['index'], (32, 224, 224, 3))\n",
        "tflite_interpreter_quant.resize_tensor_input(output_details[0]['index'], (32, 5))\n",
        "tflite_interpreter_quant.allocate_tensors()\n",
        "\n",
        "input_details = tflite_interpreter_quant.get_input_details()\n",
        "output_details = tflite_interpreter_quant.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"name:\", input_details[0]['name'])\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"name:\", output_details[0]['name'])\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugyTdiCiN2iU"
      },
      "source": [
        "# Run inference(추론을 실행하라.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbSTJHKxN2iV",
        "outputId": "17cd9bff-5909-4a4b-88e5-4e041246926d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tflite_interpreter_quant.set_tensor(input_details[0][\\'index\\'], val_image_batch)\\n\\ntflite_interpreter_quant.invoke()\\n\\ntflite_q_model_predictions = tflite_interpreter_quant.get_tensor(output_details[0][\\'index\\'])\\nprint(\"\\nPrediction results shape:\", tflite_q_model_predictions.shape)\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''tflite_interpreter_quant.set_tensor(input_details[0]['index'], val_image_batch)\n",
        "\n",
        "tflite_interpreter_quant.invoke()\n",
        "\n",
        "tflite_q_model_predictions = tflite_interpreter_quant.get_tensor(output_details[0]['index'])\n",
        "print(\"\\nPrediction results shape:\", tflite_q_model_predictions.shape)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x1I1j6iUGuF",
        "outputId": "94adb6da-454a-4883-c8f2-2a7d96b39670"
      },
      "source": [
        "# Convert prediction results to Pandas dataframe, for better visualization(더 나은 시각화를 위해 예측 결과를 Pandas 데이터 프레임으로 변환)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVjZNaSmN2iW",
        "outputId": "5141aadb-e985-4844-c352-bfa451461511"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tflite_q_pred_dataframe = pd.DataFrame(tflite_q_model_predictions)\\ntflite_q_pred_dataframe.columns = dataset_labels\\n\\nprint(\"Quantized TFLite model prediction results for the first elements\")\\ntflite_q_pred_dataframe.head()'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''tflite_q_pred_dataframe = pd.DataFrame(tflite_q_model_predictions)\n",
        "tflite_q_pred_dataframe.columns = dataset_labels\n",
        "\n",
        "print(\"Quantized TFLite model prediction results for the first elements\")\n",
        "tflite_q_pred_dataframe.head()'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuu7S1aGGF_L"
      },
      "source": [
        "## Compare prediction results (예측 결과 비교)\n",
        "\n",
        "Now we will use Pandas to visualize results from all 3 models and find differences between them.\n",
        "(이제 Pandas를 사용하여 3가지 모델 모두의 결과를 시각화하고 차이점을 찾습니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV5up55ggSdz",
        "outputId": "7ba9cbbc-860e-4651-8c3a-186aeb57ebe1"
      },
      "source": [
        "# Concatenate results from all models(모든 모델의 결과 연결)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8AND9fcN2iX",
        "outputId": "1cb7956b-e69e-49ad-ef5b-f72c4e0143b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"all_models_dataframe = pd.concat([tf_pred_dataframe, \\n                                  tflite_pred_dataframe, \\n                                  tflite_q_pred_dataframe], \\n                                 keys=['TF Model', 'TFLite', 'TFLite quantized'],\\n                                 axis='columns')\\nall_models_dataframe.head()\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''all_models_dataframe = pd.concat([tf_pred_dataframe, \n",
        "                                  tflite_pred_dataframe, \n",
        "                                  tflite_q_pred_dataframe], \n",
        "                                 keys=['TF Model', 'TFLite', 'TFLite quantized'],\n",
        "                                 axis='columns')\n",
        "all_models_dataframe.head()'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zR0JhskfuGe",
        "outputId": "a8ba3136-e167-4bd8-d0b3-191388ba02d8"
      },
      "source": [
        "# Swap columns to hava side by side comparison(나란히 비교할 수 있도록 열을 바꿉니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A2L7ZhON2iY"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "all_models_dataframe = all_models_dataframe.swaplevel(axis='columns')[tflite_pred_dataframe.columns]\n",
        "all_models_dataframe.head()'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBcQz6Jtg6vC",
        "outputId": "2427360e-be70-4dab-f920-ebeabe266ec8"
      },
      "source": [
        "# Highlight TFLite models predictions that are different from original model (원래 모델과 다른 TFLite 모델 예측 강조 표시)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3LCJMcEN2iY",
        "outputId": "ffd213ee-eab2-47af-872c-43fd4e1f165c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"def highlight_diff(data, color='yellow'):\\n    attr = 'background-color: {}'.format(color)\\n    other = data.xs('TF Model', axis='columns', level=-1)\\n    return pd.DataFrame(np.where(data.ne(other, level=0), attr, ''),\\n                        index=data.index, columns=data.columns)\\n\\nall_models_dataframe.style.apply(highlight_diff, axis=None)\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''def highlight_diff(data, color='yellow'):\n",
        "    attr = 'background-color: {}'.format(color)\n",
        "    other = data.xs('TF Model', axis='columns', level=-1)\n",
        "    return pd.DataFrame(np.where(data.ne(other, level=0), attr, ''),\n",
        "                        index=data.index, columns=data.columns)\n",
        "\n",
        "all_models_dataframe.style.apply(highlight_diff, axis=None)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdVdGpHVlMWn"
      },
      "source": [
        "As we can see, in most cases predictions are different between all models, usually by small factors. High-confidence predictions between TensorFlow and TensorFlow Lite models are very close to each other (in some cases there are even similar).  \n",
        "Quantized model outstands the most, but this is the cost of optimizations (model weights 3-4 times less).\n",
        "\n",
        "우리가 볼 수 있듯이 대부분의 경우 예측은 일반적으로 작은 요인에 의해 모든 모델 간에 다릅니다. TensorFlow와 TensorFlow Lite 모델 간의 높은 신뢰도 예측은 서로 매우 가깝습니다(어떤 경우에는 유사하기도 함).\n",
        "양자화 모델이 가장 뛰어나지만 최적화 비용입니다(모델 가중치 3~4배 적음)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UAomaI1mcjI"
      },
      "source": [
        "To make prediction results even more readable, let's simplify dataframes, to show only the highest-score prediction and the corresponding label.\n",
        "\n",
        "예측 결과를 더 읽기 쉽게 만들기 위해 데이터 프레임을 단순화하여 최고 점수 예측과 해당 레이블만 표시해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1VF39ENoaab"
      },
      "source": [
        "# Concatenation of argmax and max value for each row(# 각 행에 대한 argmax와 max 값의 연결)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9_UYjiZN2ia",
        "outputId": "5562ba76-9233-4b9f-f4c0-387db8ce3976"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'def max_values_only(data):\\n  argmax_col = np.argmax(data, axis=1).reshape(-1, 1)\\n  max_col = np.max(data, axis=1).reshape(-1, 1)\\n  return np.concatenate([argmax_col, max_col], axis=1)'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''def max_values_only(data):\n",
        "  argmax_col = np.argmax(data, axis=1).reshape(-1, 1)\n",
        "  max_col = np.max(data, axis=1).reshape(-1, 1)\n",
        "  return np.concatenate([argmax_col, max_col], axis=1)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBXnuC21N2ia"
      },
      "source": [
        "# Build simplified prediction tables(# 단순화된 예측 테이블 작성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_jm2-UlN2ib",
        "outputId": "8cc9470c-1144-41cf-8cf0-ac17be948bcd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tf_model_pred_simplified = max_values_only(tf_model_predictions)\\ntflite_model_pred_simplified = max_values_only(tflite_model_predictions)\\ntflite_q_model_pred_simplified = max_values_only(tflite_q_model_predictions)'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''tf_model_pred_simplified = max_values_only(tf_model_predictions)\n",
        "tflite_model_pred_simplified = max_values_only(tflite_model_predictions)\n",
        "tflite_q_model_pred_simplified = max_values_only(tflite_q_model_predictions)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC3mZQCbpnyF",
        "outputId": "a8269264-2a4a-45f9-bd2a-91715e4e3fc4"
      },
      "source": [
        "# Build DataFrames and present example(# DataFrame을 구축하고 예제를 제시합니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87UHCLS8N2ib",
        "outputId": "c1470e3f-3eb1-49f5-ce4e-41457a6aa59c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'columns_names = [\"Label_id\", \"Confidence\"]\\ntf_model_simple_dataframe = pd.DataFrame(tf_model_pred_simplified)\\ntf_model_simple_dataframe.columns = columns_names\\n\\ntflite_model_simple_dataframe = pd.DataFrame(tflite_model_pred_simplified)\\ntflite_model_simple_dataframe.columns = columns_names\\n\\ntflite_q_model_simple_dataframe = pd.DataFrame(tflite_q_model_pred_simplified)\\ntflite_q_model_simple_dataframe.columns = columns_names\\n\\ntf_model_simple_dataframe.head()'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''columns_names = [\"Label_id\", \"Confidence\"]\n",
        "tf_model_simple_dataframe = pd.DataFrame(tf_model_pred_simplified)\n",
        "tf_model_simple_dataframe.columns = columns_names\n",
        "\n",
        "tflite_model_simple_dataframe = pd.DataFrame(tflite_model_pred_simplified)\n",
        "tflite_model_simple_dataframe.columns = columns_names\n",
        "\n",
        "tflite_q_model_simple_dataframe = pd.DataFrame(tflite_q_model_pred_simplified)\n",
        "tflite_q_model_simple_dataframe.columns = columns_names\n",
        "\n",
        "tf_model_simple_dataframe.head()'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di0vIUMN_T0I",
        "outputId": "773e1b47-2da8-47ac-b6b5-0c1fdbd79707"
      },
      "source": [
        "# Concatenate results from all models(# 모든 모델의 결과 연결)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZZnCMqNN2ic",
        "outputId": "5bed573c-9598-412f-b52b-0521fc007de3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"all_models_simple_dataframe = pd.concat([tf_model_simple_dataframe, \\n                                         tflite_model_simple_dataframe, \\n                                         tflite_q_model_simple_dataframe], \\n                                        keys=['TF Model', 'TFLite', 'TFLite quantized'],\\n                                        axis='columns')\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''all_models_simple_dataframe = pd.concat([tf_model_simple_dataframe, \n",
        "                                         tflite_model_simple_dataframe, \n",
        "                                         tflite_q_model_simple_dataframe], \n",
        "                                        keys=['TF Model', 'TFLite', 'TFLite quantized'],\n",
        "                                        axis='columns')'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSksffZcN2id"
      },
      "source": [
        "# Swap columns for side-by-side comparison(# 나란히 비교를 위해 열 교체)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2tbpkfVN2id",
        "outputId": "44c5c271-5aa1-4957-aa1e-63ccc1853a4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"all_models_simple_dataframe = all_models_simple_dataframe.swaplevel(axis='columns')[tf_model_simple_dataframe.columns]\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''all_models_simple_dataframe = all_models_simple_dataframe.swaplevel(axis='columns')[tf_model_simple_dataframe.columns]'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoYqtH4jN2id"
      },
      "source": [
        "# Highlight differences(# 차이점 강조)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlZHqei0N2ie",
        "outputId": "9c3b90f6-6316-4ef7-a1bf-5d240d041280"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'all_models_simple_dataframe.style.apply(highlight_diff, axis=None)'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''all_models_simple_dataframe.style.apply(highlight_diff, axis=None)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGlSOG2DqjqY"
      },
      "source": [
        "## Visualize predictions from TFLite models(FLite 모델의 예측 시각화)\n",
        "\n",
        "At the end let's visualize predictions from TensorFlow Lite and quantized TensorFlow Lite models.\n",
        "\n",
        "마지막으로 TensorFlow Lite 및 양자화된 TensorFlow Lite 모델의 예측을 시각화해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqqvh-QvdB6g",
        "outputId": "13b1a360-87e6-440c-a193-8d1a32068bf8"
      },
      "source": [
        "# Print images batch and labels predictions for TFLite Model(# TFLite 모델에 대한 이미지 배치 및 레이블 예측 출력)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxEFDPA5N2if",
        "outputId": "2b232142-1e15-4813-bacd-c8c15c4211ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tflite_predicted_ids = np.argmax(tflite_model_predictions, axis=-1)\\ntflite_predicted_labels = dataset_labels[tflite_predicted_ids]\\ntflite_label_id = np.argmax(val_label_batch, axis=-1)\\n\\nplt.figure(figsize=(10,9))\\nplt.subplots_adjust(hspace=0.5)\\nfor n in range(30):\\n  plt.subplot(6,5,n+1)\\n  plt.imshow(val_image_batch[n])\\n  color = \"green\" if tflite_predicted_ids[n] == true_label_ids[n] else \"red\"\\n  plt.title(tflite_predicted_labels[n].title(), color=color)\\n  plt.axis(\\'off\\')\\n_ = plt.suptitle(\"TFLite model predictions (green: correct, red: incorrect)\")'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''tflite_predicted_ids = np.argmax(tflite_model_predictions, axis=-1)\n",
        "tflite_predicted_labels = dataset_labels[tflite_predicted_ids]\n",
        "tflite_label_id = np.argmax(val_label_batch, axis=-1)\n",
        "\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(val_image_batch[n])\n",
        "  color = \"green\" if tflite_predicted_ids[n] == true_label_ids[n] else \"red\"\n",
        "  plt.title(tflite_predicted_labels[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"TFLite model predictions (green: correct, red: incorrect)\")'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5po0e7gAw_tn"
      },
      "source": [
        "## Export image validation batch(이미지 유효성 검사 일괄 내보내기)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QabY81a16vp_"
      },
      "source": [
        "Export validation batch so it can be tested client side. Below we create compressed file containing all images named with the convention:\n",
        "\n",
        "`n{}_true{}_pred{}.jpg`\n",
        "\n",
        "where the first number is index, the second - true label index, the third - value predicted by TFLite moder generated in this notebook. Example file will look similar to this: `n0_true1_pred1.jpg`.\n",
        "\n",
        "All images then will be put into client side testing code (res/assets in Android tests). Integration tests will run inference process on each image and then compare results with the ones saved in file names.\n",
        "\n",
        "클라이언트 측에서 테스트할 수 있도록 유효성 검사 일괄 처리를 내보냅니다. 아래에서는 규칙에 따라 이름이 지정된 모든 이미지가 포함된 압축 파일을 만듭니다.\n",
        "\n",
        "`n{}_true{}_pred{}.jpg`\n",
        "\n",
        "여기서 첫 번째 숫자는 인덱스, 두 번째는 실제 레이블 인덱스, 세 번째는 이 노트북에서 생성된 TFLite 모더가 예측한 값입니다. 예제 파일은 `n0_true1_pred1.jpg`와 유사합니다.\n",
        "\n",
        "그러면 모든 이미지가 클라이언트 측 테스트 코드(Android 테스트의 res/assets)에 포함됩니다. 통합 테스트는 각 이미지에 대해 추론 프로세스를 실행한 다음 파일 이름에 저장된 결과와 결과를 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_T9n8o01wPc",
        "outputId": "1a0240f7-32e1-458e-f014-15faec0fe6ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'from PIL import Image'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''from PIL import Image'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN-a27dBpvID",
        "outputId": "fb38fec1-73d0-4b4a-e538-1d8af4373865"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'VAL_BATCH_DIR = \"validation_batch\"'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''VAL_BATCH_DIR = \"validation_batch\"'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SVlZZzEu1U9p",
        "outputId": "52731dd7-68f3-4603-924d-067ffe30f059"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!mkdir {VAL_BATCH_DIR}'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''!mkdir {VAL_BATCH_DIR}'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhWe3RrhxFZj"
      },
      "source": [
        "# Export batch to *.jpg files with specific naming convention.(# 특정 명명 규칙에 따라 배치를 *.jpg 파일로 내보냅니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty69Bi0UN2ii"
      },
      "source": [
        "# Make sure they are exported in the full quality, otherwise the inference(# 전체 품질로 내보내졌는지 확인하세요. 그렇지 않으면 추론이 가능합니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhUuDBJzN2ij"
      },
      "source": [
        "# process will return different results. (# 프로세스는 다른 결과를 반환합니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1XyxBtFN2ij"
      },
      "outputs": [],
      "source": [
        "'''for n in range(32):\n",
        "  filename = \"n{:0.0f}_true{:0.0f}_pred{:0.0f}.jpg\".format(\n",
        "      n,\n",
        "      true_label_ids[n],\n",
        "      tflite_model_pred_simplified[n][0]\n",
        "  )\n",
        "  img_arr = np.copy(val_image_batch[n])\n",
        "  img_arr *= 255\n",
        "  img_arr = img_arr.astype(\"uint8\")\n",
        "  img11 = Image.fromarray(img_arr, 'RGB')\n",
        "  img11.save(\"{}/{}\".format(VAL_BATCH_DIR, filename), \"JPEG\", quality=100)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxsY9jwkxakd"
      },
      "outputs": [],
      "source": [
        "'''!tar -zcvf {VAL_BATCH_DIR}.tar.gz {VAL_BATCH_DIR}'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93k0utqr8Mq-"
      },
      "source": [
        "File `validation_batch.tar.gz` is ready to be downloaded, unpacked and put into client-side testing code.\n",
        "\n",
        "`validation_batch.tar.gz` 파일을 다운로드하고 압축을 풀고 클라이언트 측 테스트 코드에 넣을 준비가 되었습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01TBzYh7N2ik"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Testing_TFLite_model-v2-sound-tf-fin-del-lite.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}